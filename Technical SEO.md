테크니컬 SEO (Technical SEO)
테크니컬 SEO는 자사 웹 사이트의 페이지가 검색엔진에 잘 노출될 수 있도록 기술적인 토대를 마련하는 작업입니다.
쉽게 말해, 검색 엔진의 웹 크롤러가 자사의 웹페이지를 쉽게 찾을 수 있도록 만드는 것입니다.
크롤러가 웹페이지를 쉽게 찾아 인덱싱 한다면 검색 엔진 이용자의 검색 결과에 해당 웹페이지가 표시될 가능성이 높아집니다.
테크니컬 SEO의 요소들은 코딩이나 전문적인 컴퓨터 지식을 필요로 하는 경우가 많아 마케터 입장에서 많이 어려울 수 있기 때문에 웹 사이트 개발자와의 협업을 통해 진행하는 것이 일반적입니다.
검색엔진의 평가 알고리즘에 따른 테크니컬 SEO 작업은 여러가지가 있습니다. (도메인 관리, 사이트맵, robot.txt)

1. 웹 사이트의 도메인 관리
도메인 관리는 하나의 도메인을 여러 웹 사이트 주소로 나누어 관리하는 방법을 말하는데, 서브 도메인 방식과 서브 폴더 방식이 있습니다.
서브 도메인 방식은 웹 페이지들을 각각의 독립된 도메인으로 설정해 관리하고 서브 폴더 방식은 웹 페이지들을 하위 도메인으로 확장시켜 관리합니다.

구글은 웹 페이지를 구성하는 콘텐츠와 연결 링크의 품질, 페이지 방문시간 등 다양한 요소를 평가해 도메인에 점수를 부여합니다. 
도메인 점수를 높게 받으면 검색 결과의 상단에 노출 될 수 있습니다. 
서브 도메인 방식은 독립된 4개 웹페이지의 도메인 점수를 관리해야 합니다. 
반면에, 서브 폴더 방식은 상위 페이지 하나의 점수가 하위 페이지들의 점수에 반영되기 때문에 상대적으로 도메인 점수를 관리하기에 더 효율적입니다.


2. 사이트맵 제출
사이트맵은 웹 사이트의 모든 페이지들을 목차처럼 보여주는 xml 형식의 파일을 말합니다. 
사이트맵 파일을 제출하면 일반적인 크롤링 과정에서 발견하지 못한 페이지들도 문제 없이 크롤링 인덱싱 될 수 있습니다.
사이트맵은 전세계적으로 정해진 양식이 존재하는데, 그 양식에 따라 사이트맵을 만들고 관리한다면 SEO 작업에 큰 도움이 됩니다.
사이트맵 제작이 어렵다면 무료로 사이트맵을 생성해주는 사이트를 이용하는 것도 방법입니다.


3. ROBOT.TXT
robot.txt파일은 검색 엔진의 웹 크롤러(검색 로봇)에게 사이트 맵의 위치를 안내하고 특정 웹 크롤러가 웹 페이지의 정보를 수집하는 것을 차단합니다.
최대한 많은 검색 결과에 웹 페이지를 노출시켜야하는 SEO에서 특정 웹 페이지의 수집을 차단해야하는 이유는 크롤러가 중복된 콘텐츠의 웹 페이지를 제한 없이 수집할 경우 검색엔진의 평가에 부정적인 영향을 미칠 수 있기 때문입니다.
특히 구글의 경우 중복 콘텐츠에 대한 패널티가 있기 때문에 robot.txt파일을 통해 크롤러의 정보 수집을 적적하게 제한할 필요가 있습니다.
robot.txt 파일은 일반 텍스트 파일로 작성하며 사이트의 루트 디렉토리에 위치시켜 설정 할 수 있습니다. 
